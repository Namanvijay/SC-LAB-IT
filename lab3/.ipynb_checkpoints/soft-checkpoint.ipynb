{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import operator\n",
    "from math import e\n",
    "from math import pi\n",
    "from sklearn.model_selection import KFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=pd.read_csv('Iris.csv')\n",
    "data=iris.iloc[:,[1,2,3,4]].values.tolist()\n",
    "y=iris.iloc[:,5].values.tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_class(data_list,x):\n",
    "    \n",
    "    group={}\n",
    "    group['Iris-virginica']=[]\n",
    "    group['Iris-setosa']=[]\n",
    "    group['Iris-versicolor']=[]\n",
    "    for i in data_list:\n",
    "        if(y[i]=='Iris-setosa'):\n",
    "            group['Iris-setosa'].append(data[i])\n",
    "        elif(y[i]=='Iris-versicolor'):\n",
    "            group['Iris-versicolor'].append(data[i])\n",
    "        if(y[i]=='Iris-virginica'):\n",
    "            group['Iris-virginica'].append(data[i])\n",
    "    return group\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_pdf(x, mean, stdev):\n",
    "        variance = stdev ** 2\n",
    "        exp_squared_diff = (x - mean) ** 2\n",
    "        exp_power = -exp_squared_diff / (2 * variance)\n",
    "        exponent = e ** exp_power\n",
    "        denominator = ((2 * pi) ** .5) * stdev\n",
    "        normal_prob = exponent / denominator\n",
    "        return normal_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mean_data(data):\n",
    "    return np.mean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_data(data):\n",
    "    return np.std(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_prob(group,target,data):\n",
    "    return len(group[target])/(data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(features):\n",
    "    for feature in zip(*features):\n",
    "            yield {\n",
    "                'stdev': std_data(feature),\n",
    "                'mean': mean_data(feature)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_prob(row,summaries):\n",
    "        joint_probs = {}\n",
    "        for target, features in summaries.items():\n",
    "            total_features = len(features['summary'])\n",
    "            likelihood = 1\n",
    "            for index in range(total_features):\n",
    "                feature = row[index]\n",
    "                mean = features['summary'][index]['mean']\n",
    "                stdev = features['summary'][index]['stdev']\n",
    "                normal_prob = normal_pdf(feature, mean, stdev)\n",
    "                likelihood *= normal_prob\n",
    "            prob = features['prob']\n",
    "            joint_probs[target] =prob * likelihood\n",
    "        return joint_probs\n",
    "\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test,summaries):\n",
    "    classes=[]\n",
    "    for i in test:\n",
    "        row=data[i]\n",
    "\n",
    "        joint_probs=joint_prob(row,summaries)\n",
    "        marginal_prob=sum(joint_probs.values())\n",
    "        post_prob={}\n",
    "#         print(joint_probs)\n",
    "#         print(marginal_prob)\n",
    "        for target,prob in joint_probs.items():\n",
    "            post_prob[target]=prob/marginal_prob\n",
    "#         print(post_prob)\n",
    "        x=max(post_prob,key=post_prob.get)\n",
    "       \n",
    "        classes.append(x)\n",
    "    return classes\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_mat(classes,test_index,x):\n",
    "   \n",
    "    rows,cols=(3,3)\n",
    "    n=0\n",
    "    cm=[[0 for i in range(cols)] for j in range(rows)]\n",
    "    for i in test_index:\n",
    "        if(y[i]=='Iris-virginica'):\n",
    "            if(classes[n]=='Iris-virginica'):\n",
    "                cm[0][0]+=1\n",
    "            elif(classes[n]=='Iris-setosa'):\n",
    "                cm[0][1]+=1\n",
    "            else:\n",
    "                cm[0][2]+=1\n",
    "            \n",
    "        elif(y[i]=='Iris-setosa'):\n",
    "            if(classes[n]=='Iris-virginica'):\n",
    "                cm[1][0]+=1\n",
    "            elif(classes[n]=='Iris-setosa'):\n",
    "                cm[1][1]+=1\n",
    "            else:\n",
    "                cm[1][2]+=1\n",
    "        else:\n",
    "            if(classes[n]=='Iris-virginica'):\n",
    "                cm[2][0]+=1\n",
    "            elif(classes[n]=='Iris-setosa'):\n",
    "                cm[2][1]+=1\n",
    "            else:\n",
    "                cm[2][2]+=1\n",
    "        n+=1\n",
    "    print(\"  Confusion Matrix\")\n",
    "\n",
    "    print(cm)\n",
    "    sp=[]\n",
    "    tp=[0 for i in range(3)]\n",
    "    fp=[0 for i in range(3)]\n",
    "    fn=[0 for i in range(3)]\n",
    "    tn=[0 for i in range(3)]\n",
    "    spp=[]\n",
    "    tp[0]=cm[0][0]\n",
    "    tp[1]=cm[1][1]\n",
    "    tp[2]=cm[2][2]\n",
    "    tn[0]=cm[1][1]+cm[2][2]\n",
    "    tn[1]=cm[0][0]+cm[2][2]\n",
    "    tn[2]=cm[0][0]+cm[1][1]\n",
    "    fn[0]=cm[0][1]+cm[0][2]\n",
    "    fn[1]=cm[1][0]+cm[1][2]\n",
    "    fn[2]=cm[2][0]+cm[2][1]\n",
    "    fp[0]=cm[1][0]+cm[2][0]\n",
    "    fp[1]=cm[0][1]+cm[2][1]\n",
    "    fp[2]=cm[1][2]+cm[0][2]\n",
    "    for i in range(3):\n",
    "        if tp[i]==0 and fn[i]==0:\n",
    "            if fp[i]==0:\n",
    "                sp.append(1.0)\n",
    "            else:\n",
    "                sp.append(0.0)\n",
    "        else:\n",
    "            x=tp[i]/(tp[i]+fn[i])\n",
    "            sp.append(x)\n",
    "    print(\"  Sensitivity is {}\".format(np.mean(sp)))\n",
    "  \n",
    "\n",
    "    for i in range(3):\n",
    "        if tn[i]==0 and fp[i]==0:\n",
    "            if fn[i]==0:\n",
    "                spp.append(1.0)\n",
    "            else:\n",
    "                spp.append(0.0)\n",
    "        else:\n",
    "            x=tn[i]/(tn[i]+fp[i])\n",
    "            spp.append(x)\n",
    "    print(\"  Specificity is {}\".format(np.mean(spp)))\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "  \n",
    " \n",
    "   \n",
    "\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(classes,test_list,x):\n",
    "    corr=0\n",
    "    n=0\n",
    "    test_list=test_list.tolist()\n",
    "\n",
    "    for i in test_list:\n",
    "       \n",
    "        if(y[i]==classes[n]):\n",
    "            corr+=1\n",
    "        n+=1\n",
    "    return corr/len(test_list)\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold States------------->\n",
      "  Confusion Matrix\n",
      "[[0, 0, 0], [0, 15, 0], [0, 0, 0]]\n",
      "  Sensitivity is 1.0\n",
      "  Specificity is 1.0\n",
      "  Accuracy is 100.0\n",
      "2 fold States------------->\n",
      "  Confusion Matrix\n",
      "[[0, 0, 0], [0, 15, 0], [0, 0, 0]]\n",
      "  Sensitivity is 1.0\n",
      "  Specificity is 1.0\n",
      "  Accuracy is 100.0\n",
      "3 fold States------------->\n",
      "  Confusion Matrix\n",
      "[[0, 0, 0], [0, 15, 0], [0, 0, 0]]\n",
      "  Sensitivity is 1.0\n",
      "  Specificity is 1.0\n",
      "  Accuracy is 100.0\n",
      "4 fold States------------->\n",
      "  Confusion Matrix\n",
      "[[0, 0, 0], [0, 5, 0], [1, 0, 9]]\n",
      "  Sensitivity is 0.6333333333333333\n",
      "  Specificity is 0.9777777777777779\n",
      "  Accuracy is 93.33333333333333\n",
      "5 fold States------------->\n",
      "  Confusion Matrix\n",
      "[[0, 0, 0], [0, 0, 0], [1, 0, 14]]\n",
      "  Sensitivity is 0.6444444444444445\n",
      "  Specificity is 0.6444444444444445\n",
      "  Accuracy is 93.33333333333333\n",
      "6 fold States------------->\n",
      "  Confusion Matrix\n",
      "[[0, 0, 0], [0, 0, 0], [2, 0, 13]]\n",
      "  Sensitivity is 0.6222222222222222\n",
      "  Specificity is 0.6222222222222222\n",
      "  Accuracy is 86.66666666666667\n",
      "7 fold States------------->\n",
      "  Confusion Matrix\n",
      "[[5, 0, 0], [0, 0, 0], [0, 0, 10]]\n",
      "  Sensitivity is 1.0\n",
      "  Specificity is 1.0\n",
      "  Accuracy is 100.0\n",
      "8 fold States------------->\n",
      "  Confusion Matrix\n",
      "[[13, 0, 2], [0, 0, 0], [0, 0, 0]]\n",
      "  Sensitivity is 0.6222222222222222\n",
      "  Specificity is 0.6222222222222222\n",
      "  Accuracy is 86.66666666666667\n",
      "9 fold States------------->\n",
      "  Confusion Matrix\n",
      "[[13, 0, 2], [0, 0, 0], [0, 0, 0]]\n",
      "  Sensitivity is 0.6222222222222222\n",
      "  Specificity is 0.6222222222222222\n",
      "  Accuracy is 86.66666666666667\n",
      "10 fold States------------->\n",
      "  Confusion Matrix\n",
      "[[15, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
      "  Sensitivity is 1.0\n",
      "  Specificity is 1.0\n",
      "  Accuracy is 100.0\n",
      "     Average Accuracy of the model is 94.66666666666667\n"
     ]
    }
   ],
   "source": [
    "kf=KFold(n_splits=10, shuffle=False)\n",
    "acc_mean=[]\n",
    "x=0\n",
    "for train_index, test_index in kf.split(iris):\n",
    "\n",
    "    group=group_class(train_index,x)\n",
    "\n",
    "    summaries = {}\n",
    "    for target,features in group.items():\n",
    "        summaries[target]={\n",
    "            'prob':class_prob(group, target, len(train_index)),\n",
    "            'summary': [i for i in fun(features)],\n",
    "        }\n",
    "    test=group_class(test_index,x)\n",
    "    classes=predict(test_index,summaries)\n",
    "    print(\"{} fold States------------->\".format(x+1))\n",
    "    \n",
    "        \n",
    "   \n",
    "    \n",
    "    acc=accuracy(classes,test_index,x)\n",
    "    acc_mean.append(acc)\n",
    "    \n",
    "    confusion_mat(classes,test_index,x)\n",
    "    print(\"  Accuracy is {}\".format(acc*100))\n",
    "    \n",
    "    x+=1\n",
    "    \n",
    "print(\"     Average Accuracy of the model is {}\".format(np.mean(acc_mean)*100))\n",
    "    \n",
    "    \n",
    "\n",
    "       \n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
